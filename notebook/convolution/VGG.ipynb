{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#VGG-Blocks\" data-toc-modified-id=\"VGG-Blocks-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>VGG Blocks</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Blocks\n",
    "<img src='../images/vvg.jpg'>\n",
    "The function takes two arguments corresponding to the number of convolutional layers num_convs and the number of output channels num_channels\n",
    "\n",
    "\n",
    "To read more on VGG visit :\n",
    "\n",
    "<a href='https://arxiv.org/pdf/1409.1556.pdf'>VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/vgg.png'>\n",
    "The original VGG network had 5 convolutional blocks, among which the first two have one convolutional layer each and the latter three contain two convolutional layers each but we will implement the vgg diagram above of which the first two have two convolutional layer each and the latter three contain three convolutional layers each.\n",
    "\n",
    "The first block has 64 output channels and each subsequent block doubles the number of output channels, until that number reaches 512. Since this network uses 8 convolutional layers and 3 fully-connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_1():\n",
    "    return tf.keras.models.Sequential([\n",
    "        layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=2,strides=2),\n",
    "        \n",
    "        layers.Conv2D(128,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(128,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=2,strides=2),\n",
    "        \n",
    "        layers.Conv2D(256,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(256,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(256,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=2,strides=2),\n",
    "        \n",
    "        layers.Conv2D(512,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(512,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(512,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=2,strides=2),\n",
    "        \n",
    "        layers.Conv2D(512,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(512,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.Conv2D(512,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=2,strides=2),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096,activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(4096,activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10)\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs,filters):\n",
    "    blk=tf.keras.models.Sequential()\n",
    "    for _ in range(num_convs):\n",
    "        blk.add(layers.Conv2D(filters,kernel_size=3,padding='same',activation='relu'))\n",
    "    blk.add(layers.MaxPool2D(pool_size=2,strides=2))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_arch = ((2, 64), (2, 128), (3, 256), (3, 512), (3, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    blk=tf.keras.models.Sequential()\n",
    "    for (num_convs,filters) in conv_arch:\n",
    "        blk.add(vgg_block(num_convs,filters))\n",
    "    blk.add(layers.Flatten())\n",
    "    blk.add(layers.Dense(4096,activation='relu'))\n",
    "    blk.add(layers.Dropout(0.5))\n",
    "    blk.add(layers.Dense(4096,activation='relu'))\n",
    "    blk.add(layers.Dropout(0.5))\n",
    "    blk.add(layers.Dense(10))\n",
    "    return blk\n",
    "\n",
    "vgg_2 = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will construct a single-channel data example with a height and width of 224 to observe\n",
    "the output shape of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D output shape:\t (1, 224, 224, 64)\n",
      "Conv2D output shape:\t (1, 224, 224, 64)\n",
      "MaxPooling2D output shape:\t (1, 112, 112, 64)\n",
      "Conv2D output shape:\t (1, 112, 112, 128)\n",
      "Conv2D output shape:\t (1, 112, 112, 128)\n",
      "MaxPooling2D output shape:\t (1, 56, 56, 128)\n",
      "Conv2D output shape:\t (1, 56, 56, 256)\n",
      "Conv2D output shape:\t (1, 56, 56, 256)\n",
      "Conv2D output shape:\t (1, 56, 56, 256)\n",
      "MaxPooling2D output shape:\t (1, 28, 28, 256)\n",
      "Conv2D output shape:\t (1, 28, 28, 512)\n",
      "Conv2D output shape:\t (1, 28, 28, 512)\n",
      "Conv2D output shape:\t (1, 28, 28, 512)\n",
      "MaxPooling2D output shape:\t (1, 14, 14, 512)\n",
      "Conv2D output shape:\t (1, 14, 14, 512)\n",
      "Conv2D output shape:\t (1, 14, 14, 512)\n",
      "Conv2D output shape:\t (1, 14, 14, 512)\n",
      "MaxPooling2D output shape:\t (1, 7, 7, 512)\n",
      "Flatten output shape:\t (1, 25088)\n",
      "Dense output shape:\t (1, 4096)\n",
      "Dropout output shape:\t (1, 4096)\n",
      "Dense output shape:\t (1, 4096)\n",
      "Dropout output shape:\t (1, 4096)\n",
      "Dense output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform(shape=(1, 224, 224,1))\n",
    "for layer in vgg_1().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t (1, 112, 112, 64)\n",
      "Sequential output shape:\t (1, 56, 56, 128)\n",
      "Sequential output shape:\t (1, 28, 28, 256)\n",
      "Sequential output shape:\t (1, 14, 14, 512)\n",
      "Sequential output shape:\t (1, 7, 7, 512)\n",
      "Flatten output shape:\t (1, 25088)\n",
      "Dense output shape:\t (1, 4096)\n",
      "Dropout output shape:\t (1, 4096)\n",
      "Dense output shape:\t (1, 4096)\n",
      "Dropout output shape:\t (1, 4096)\n",
      "Dense output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform(shape=(1, 224, 224,1))\n",
    "for layer in vgg_2.layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
