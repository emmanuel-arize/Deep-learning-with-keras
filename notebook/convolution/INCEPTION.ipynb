{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#INCEPTION\" data-toc-modified-id=\"INCEPTION-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>INCEPTION</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INCEPTION\n",
    "<img src=\"../images/inception.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogLeNet uses a stack of a total of 9 inception blocks and global average pooling to generate its estimates. Maximum pooling between inception blocks reduced the\n",
    "dimensionality. The first part is identical to AlexNet and LeNet, the stack of blocks is inherited\n",
    "from VGG and the global average pooling avoids a stack of fully-connected layers at the end. The\n",
    "architecture is depicted below\n",
    "<img src=\"../images/inception1.jpg\" />\n",
    "<img src=\"../images/inception2.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_block(tf.keras.Model):\n",
    "    def __init__(self,c1,c2,c3,c4,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Path 1 is a single 1 x 1 convolutional layer\n",
    "        self.p1_1=layers.Conv2D(filters=c1,kernel_size=1,activation='relu')\n",
    "        # Path 2 is a 1 x 1 convolutional layer followed by a 3 x 3\n",
    "        # convolutional layer\n",
    "        self.p2_1=layers.Conv2D(filters=c2[0],kernel_size=1,activation='relu')\n",
    "        self.p2_2=layers.Conv2D(filters=c2[1],kernel_size=3,padding='same',activation='relu')\n",
    "         # Path 2 is a 1 x 1 convolutional layer followed by a 5 x 5\n",
    "        # convolutional layer\n",
    "        self.p3_1=layers.Conv2D(filters=c3[0],kernel_size=1,activation='relu')\n",
    "        self.p3_2=layers.Conv2D(filters=c3[1],kernel_size=5,padding='same',activation='relu')\n",
    "         # Path 4 is a 3 x 3 maximum pooling layer followed by a 1 x 1\n",
    "        # convolutional layer\n",
    "        self.p4_1=layers.MaxPool2D(pool_size=3,padding='same',strides=1)\n",
    "        self.p4_2=layers.Conv2D(filters=c4,kernel_size=1,activation='relu')\n",
    "    def call(self,x):\n",
    "        p1=self.p1_1(x)\n",
    "        p2=self.p2_2(self.p2_1(x))\n",
    "        p3=self.p3_2(self.p3_1(x))\n",
    "        p4=self.p4_2(self.p4_1(x))\n",
    "        return layers.Concatenate()([p1, p2, p3, p4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception():\n",
    "    return tf.keras.models.Sequential([\n",
    "        layers.Conv2D(filters=64,kernel_size=7,strides=2,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=3,padding='same',strides=2),\n",
    "        \n",
    "        layers.Conv2D(64,kernel_size=1,activation='relu'),\n",
    "        layers.Conv2D(192,kernel_size=3,padding='same',activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=3,padding='same',strides=2),\n",
    "        # inception(3a)\n",
    "        Inception_block(c1=64,c2=(96,128),c3=(16,32),c4=32),\n",
    "               # inception(3b)\n",
    "        Inception_block(c1=128,c2=(128,192),c3=(32,96),c4=64),\n",
    "        layers.MaxPool2D(pool_size=3,padding='same',strides=2),\n",
    "        # inception(4a)\n",
    "        Inception_block(c1=192,c2=(96,208),c3=(16,48),c4=64),\n",
    "              # inception(4b)\n",
    "        Inception_block(c1=160,c2=(112,224),c3=(24,64),c4=64),\n",
    "        # inception(4c)\n",
    "        Inception_block(c1=128,c2=(128,256),c3=(24,64),c4=64),\n",
    "        # inception(4d)\n",
    "        Inception_block(112,(144,288),(32,64),64),\n",
    "        # inception(4e)\n",
    "        Inception_block(256,(160,320),(32,128),128),\n",
    "        layers.MaxPool2D(pool_size=3,padding='same',strides=2),\n",
    "         # inception(5a)\n",
    "        Inception_block(256, (160, 320), (32, 128), 128),\n",
    "              # inception(5b)\n",
    "        Inception_block(384, (192, 384), (48, 128), 128),\n",
    "        layers.MaxPool2D(pool_size=3,padding='same',strides=2),\n",
    "        layers.GlobalAvgPool2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(10,activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D output shape:\t (1, 1, 48, 64)\n",
      "MaxPooling2D output shape:\t (1, 1, 24, 64)\n",
      "Conv2D output shape:\t (1, 1, 24, 64)\n",
      "Conv2D output shape:\t (1, 1, 24, 192)\n",
      "MaxPooling2D output shape:\t (1, 1, 12, 192)\n",
      "Inception_block output shape:\t (1, 1, 12, 256)\n",
      "Inception_block output shape:\t (1, 1, 12, 480)\n",
      "MaxPooling2D output shape:\t (1, 1, 6, 480)\n",
      "Inception_block output shape:\t (1, 1, 6, 512)\n",
      "Inception_block output shape:\t (1, 1, 6, 512)\n",
      "Inception_block output shape:\t (1, 1, 6, 512)\n",
      "Inception_block output shape:\t (1, 1, 6, 528)\n",
      "Inception_block output shape:\t (1, 1, 6, 832)\n",
      "MaxPooling2D output shape:\t (1, 1, 3, 832)\n",
      "Inception_block output shape:\t (1, 1, 3, 832)\n",
      "Inception_block output shape:\t (1, 1, 3, 1024)\n",
      "MaxPooling2D output shape:\t (1, 1, 2, 1024)\n",
      "GlobalAveragePooling2D output shape:\t (1, 1024)\n",
      "Flatten output shape:\t (1, 1024)\n",
      "Dropout output shape:\t (1, 1024)\n",
      "Dense output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform(shape=(1, 1, 96, 96))\n",
    "for layer in inception().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
